+++
title = "Kafka"
weight = 12
+++
# Kод Terraform для автоматического развертывания и управления кластером Apache Kafka в Kubernetes с использованием [Strimzi Kafka Operator](https://strimzi.io/).

## Обзор

Данное решение позволяет декларативно управлять всеми аспектами кластера Kafka: от его развертывания до создания топиков и пользователей. Strimzi Operator значительно упрощает эксплуатацию Kafka в среде Kubernetes, автоматизируя сложные задачи.

### Ключевые особенности

*   **Инфраструктура как код (IaC)**: Полное управление жизненным циклом Kafka через Terraform.
*   **Развертывание через Strimzi**: Использование CRD (Custom Resource Definitions) Strimzi для надежного создания и управления кластером.
*   **Автоматизация**: Автоматическое создание пространства имен, кластера Kafka, топиков и пользователей.
*   **Гибкая конфигурация**: Параметры кластера, такие как количество реплик, конфигурация хранилища и топиков, легко настраиваются через переменные Terraform.
*   **Безопасность**: Встроенная поддержка создания пользователей с аутентификацией SCRAM-SHA-512 и TLS-шифрованием.
*   **Внешний доступ**: Настройка внешнего доступа к брокерам через Ingress.

## Предварительные требования

1.  **Kubernetes Кластер**: Доступ к работающему кластеру Kubernetes.
2.  **kubectl**: Установленный и настроенный `kubectl` для доступа к вашему кластеру.
3.  **Terraform**: Установленный Terraform (версия 1.x или выше).
4.  **Ingress Controller**: В кластере должен быть установлен Ingress Controller (например, Traefik, NGINX). `traefik` используется по умолчанию.
5.  **StorageClass**: Наличие `StorageClass` для динамического выделения постоянных томов (PVC). `linstor-storage` используется по умолчанию.
6.  **DNS**: Предварительно настроенные DNS-записи, указывающие на ваш Ingress Controller для хостов, указанных в переменных `bootstrap_host` и `broker_hosts`.

## 3-х этапная модель установки

Хотя вся конфигурация применяется одной командой `terraform apply`, внутренне процесс развертывания можно разделить на три логических этапа, которые Terraform выполняет в правильном порядке благодаря зависимостям (`depends_on`).

### Этап 1: Установка Strimzi Operator

**Что происходит?**
На этом этапе создается основа для нашего кластера Kafka.
1.  **Namespace**: Terraform создает выделенное пространство имен Kubernetes (по умолчанию `kafka`), чтобы изолировать все ресурсы, связанные с Kafka.
2.  **Strimzi Operator**: С помощью Helm-чарта в это пространство имен устанавливается Strimzi Kafka Operator.

**Анализ и особенности:**
*   **Оператор-ориентированный подход**: Вместо того чтобы управлять подами Kafka напрямую, мы делегируем эту задачу оператору. Оператор следит за состоянием кастомных ресурсов (таких как `Kafka`, `KafkaTopic`) и приводит кластер в соответствие с их спецификациями. Это значительно повышает надежность и упрощает обновления.
*   **Идемпотентность**: Все ресурсы создаются идемпотентно. Повторное применение конфигурации не вызовет ошибок, а лишь приведет систему в требуемое состояние.

### Этап 2: Развертывание кластера Kafka

**Что происходит?**
После того как оператор запущен и готов к работе, Terraform создает кастомный ресурс `Kafka`.
1.  **Kafka CRD**: Terraform отправляет в Kubernetes манифест `Kafka`, описывающий желаемую конфигурацию кластера:
    *   Количество брокеров (`kafka_replicas`).
    *   Количество узлов Zookeeper (`zk_replicas`).
    *   Конфигурация хранилища (`storage_class`).
    *   Настройки слушателей (listeners) для внутреннего и внешнего доступа.

**Анализ и особенности:**
*   **Декларативность**: Мы не описываем, *как* создать кластер, а лишь *каким* он должен быть. Strimzi Operator берет на себя всю сложную логику: создание `StatefulSet` для брокеров и Zookeeper, управление PVC, настройку `Service` и `Ingress`.
*   **Масштабируемость**: Для масштабирования кластера достаточно изменить переменную `kafka_replicas` и применить конфигурацию. Strimzi безопасно добавит новые брокеры в кластер.

### Этап 3: Создание ресурсов (Топики и Пользователи)

**Что происходит?**
Когда кластер Kafka полностью готов, Terraform создает остальные ресурсы.
1.  **KafkaTopic CRD**: Для каждого элемента в переменной `topics` создается ресурс `KafkaTopic`. Оператор Strimzi автоматически создает эти топики в Kafka с указанными параметрами (количество партиций, репликация, политика хранения).
2.  **KafkaUser CRD**: Если `create_user_streamforge` установлено в `true`, создается ресурс `KafkaUser`. Оператор создает пользователя и генерирует для него секрет Kubernetes с учетными данными для аутентификации SCRAM-SHA-512.

**Анализ и особенности:**
*   **Управление через GitOps**: Конфигурация топиков и пользователей хранится в коде (`variables.tf`), что идеально подходит для GitOps-подхода. Любые изменения версионируются и применяются через стандартный пайплайн CI/CD.
*   **Безопасность по умолчанию**: Пользователи создаются с надежным методом аутентификации. Секреты генерируются автоматически и хранятся в Kubernetes, что безопаснее, чем хранить их в виде открытого текста.

## Установка и использование

### 1. Инициализация Terraform
Выполните эту команду в каталоге `/infra/kafka`:
```bash
terraform init
```

### 2. Настройка переменных
Создайте файл `terraform.tfvars` или измените переменные в `variables.tf` для соответствия вашей среде.

**Пример `terraform.tfvars`:**
```hcl
# Имя домена для внешнего доступа
domain = "my-cluster.com"

# Имена хостов должны быть разрешены вашим DNS
bootstrap_host = "kafka-bootstrap.my-cluster.com"
broker_hosts = [
  "kafka-0.my-cluster.com",
  "kafka-1.my-cluster.com",
  "kafka-2.my-cluster.com",
]

# StorageClass, доступный в вашем кластере
storage_class = "standard-rwo"

# Список топиков для создания
topics = [
  { name = "prod-events", partitions = 10, replicas = 3, retention_ms = 604800000, cleanup_policy = "delete" },
  { name = "prod-metrics", partitions = 5, replicas = 3, retention_ms = 86400000,  cleanup_policy = "delete" },
]
```

### 3. Развертывание
Примените конфигурацию:
```bash
terraform apply
```
Terraform покажет план и запросит подтверждение. После ввода `yes` начнется процесс развертывания.

## Получение учетных данных

После успешного развертывания Terraform выведет имена секретов, содержащих CA-сертификат кластера и пароль пользователя.

*   `cluster_ca_secret_name`: Имя секрета с CA-сертификатом (`k3-cluster-ca-cert`).
*   `user_streamforge_secret_name`: Имя секрета с паролем пользователя (`user-streamforge`).

**Чтобы получить пароль пользователя:**
```bash
kubectl get secret user-streamforge -n kafka -o jsonpath='{.data.password}' | base64 -d
```

**Чтобы получить CA сертификат:**
```bash
kubectl get secret k3-cluster-ca-cert -n kafka -o jsonpath='{.data.ca\.crt}' | base64 -d > ca.crt
```

Эти данные необходимы вашим клиентам для подключения к Kafka.

---

## Развертывание в GKE Autopilot

Развертывание в среде GKE Autopilot требует нескольких специфических изменений в конфигурации из-за особенностей этой платформы. Autopilot управляет узлами и ресурсами автоматически, что накладывает определенные ограничения.

### Ключевые изменения для Autopilot

1.  **StorageClass**: GKE Autopilot не поддерживает кастомные `StorageClass`, такие как `linstor-storage`. Необходимо использовать стандартные классы хранения, предоставляемые Google Cloud.
    *   **Решение**: Измените переменную `storage_class` на `standard-rwo` (для стандартных постоянных дисков) или `premium-rwo` (для SSD).

2.  **Ingress Controller**: Вместо `traefik` рекомендуется использовать нативный GKE Ingress. 
    *   **Решение**: Установите значение переменной `ingress_class` равным `"gce"`. Однако, обратите внимание, что шаблону `k3-kafka.yaml.tmpl` может потребоваться доработка для добавления специфичных для GKE Ingress аннотаций, если они не создаются автоматически.

3.  **Запросы ресурсов (Resource Requests)**: GKE Autopilot имеет строгие правила по управлению ресурсами CPU и Memory. Strimzi позволяет задавать эти параметры в своих CRD.
    *   **Рекомендация**: Проверьте файл шаблона `templates/k3-kafka.yaml.tmpl`. Если в нем жестко заданы запросы к ресурсам (`requests` и `limits`) для Kafka или Zookeeper, убедитесь, что они соответствуют диапазонам, разрешенным в Autopilot. В противном случае Autopilot может отклонить создание подов. Часто лучше позволить Autopilot управлять ресурсами, удалив эти поля из шаблона.

### Пример конфигурации для GKE Autopilot

Создайте файл `terraform.tfvars` со следующими изменениями:

```hcl
# Используйте стандартный StorageClass для GKE
storage_class = "standard-rwo"

# Укажите класс Ingress для GKE. 
# Возможно, потребуется настройка аннотаций в шаблоне k3-kafka.yaml.tmpl
ingress_class = "gce"

# Убедитесь, что ваш домен и DNS-записи настроены
# для работы с внешним IP-адресом, который будет создан GKE Ingress
domain = "gke.my-company.com"
bootstrap_host = "kafka-bootstrap.gke.my-company.com"
broker_hosts = [
  "kafka-0.gke.my-company.com",
  "kafka-1.gke.my-company.com",
  "kafka-2.gke.my-company.com",
]
```

### Процесс развертывания

Процесс развертывания остается прежним: `terraform init`, `terraform plan`, `terraform apply`. Однако перед применением конфигурации убедитесь, что все вышеуказанные изменения внесены, чтобы избежать ошибок, специфичных для среды Autopilot.