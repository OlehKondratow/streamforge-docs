+++
date = '2025-08-24T20:23:59+02:00'
draft = true
title = 'Инфраструктура и окружение'
weight = 3
+++

## Часть III: Инфраструктура и окружение

Платформа **StreamForge** развернута в высокопроизводительной локальной среде, спроектированной для максимальной надежности, масштабируемости и операционной эффективности. Инфраструктура построена на тщательно подобранном стеке корпоративных технологий с открытым исходным кодом. В ее основе лежит кластер **Kubernetes**, работающий в виртуализированной среде и управляемый с помощью современных методологий GitOps и облачных архитектурных паттернов.

### Глава 5: Основы платформы: Kubernetes и виртуализация

#### 5.1. Фундамент: Proxmox VE

**Proxmox VE** служит основополагающим уровнем виртуализации — зрелой платформой корпоративного уровня, обеспечивающей надежную изоляцию вычислительных сред, высокую доступность и централизованное управление ресурсами. Виртуальные машины, развернутые на Proxmox VE, служат хостами для узлов кластера Kubernetes.

#### 5.2. Развертывание кластера: Kubespray

Кластер Kubernetes развертывается с помощью **Kubespray** — соответствующего стандартам CNCF автоматизированного инструмента для готовых к эксплуатации сред. Kubespray обеспечивает идемпотентный и повторяемый процесс развертывания, охватывающий установку плоскости управления, настройку топологии сети и интеграцию TLS, что гарантирует согласованность и воспроизводимость кластера.

#### 5.3. Сетевая инфраструктура

Сетевая инфраструктура StreamForge спроектирована для высокой надежности и адаптируемости с упором на отказоустойчивость и прозрачный внешний доступ:

- **kube-vip** предоставляет виртуальный IP-адрес для высокодоступного (HA) доступа к API Kubernetes, обеспечивая автоматическое перенаправление трафика в случае сбоя узла плоскости управления.
- **MetalLB** версии `0.14.9` используется в режиме Layer2 для поддержки сервисов типа `LoadBalancer` в среде без операционной системы, устраняя необходимость в аппаратном балансировщике нагрузки.

#### 5.4. Ingress и Gateway API: управление трафиком

В StreamForge используется двойная стратегия контроллеров Ingress для управления входящим трафиком, обеспечивая гибкую маршрутизацию и высокую доступность:

- **Traefik** (v36.1.0) — основной контроллер Ingress, использующий новый **Gateway API** для декларативной маршрутизации и управления трафиком на уровнях L7 (HTTP/HTTPS) и L4 (TCP/UDP).
- **ingress-nginx** (v4.12.1) — резервный контроллер Ingress, обеспечивающий совместимость и дополнительную отказоустойчивость.

Настройки включают:
- TLS через `cert-manager` и внутренний ЦС `homelab-ca-issuer`
- Внешний IP: `192.168.1.153`
- Хранилище ACME: 1Gi NFS
- Мониторинг через `/dashboard`
- Поддержка сервисов TCP (`ssh`, `kafka`)

#### 5.5. DNS и TLS

- **Technitium DNS Server** предоставляет локальный сопоставитель с поддержкой произвольных зон DNS, включая `*.dmz.home`, обеспечивая доступ к сервисам по понятным для человека именам.
- **cert-manager** автоматизирует управление сертификатами TLS, снижая риск ошибок и повышая безопасность обмена данными между компонентами.

##### `script.sh` для генерации сертификатов TLS

Скрипт `/platform/base/cert/script.sh` автоматизирует полный жизненный цикл генерации сертификатов TLS, включая:
1. Настройку параметров генерации и хранения;
2. Создание CSR с полями SAN (FQDN + IP);
3. Формирование ресурса `CertificateRequest` и отправку его в `cert-manager`;
4. Ожидание выполнения и сохранение файлов PEM;
5. Проверку сертификата через `openssl`.

---

### Глава 6: Управление данными: стратегии хранения и доступа

Постоянное хранение данных является критически важным аспектом для обеспечения долгосрочной аналитики и эффективного обучения моделей. В StreamForge хранение данных сегментировано по функциональным зонам для оптимизации производительности и доступности.

#### 6.1. Обзор решений для хранения данных

- **Linstor Piraeus** — отказоустойчивое блочное хранилище (RWO) для критически важных сервисов, таких как PostgreSQL и ArangoDB, обеспечивающее высокую доступность и целостность данных.
- **GlusterFS** и **NFS Subdir External Provisioner** (v4.0.18) — предоставляют общие тома с режимом доступа RWX (ReadWriteMany), что идеально подходит для сред совместной работы, таких как JupyterHub, и для общих наборов данных. Основной путь доступа — `192.168.1.6:/data0/k2`.

#### 6.2. Объектное хранилище Minio

- **Minio** — S3-совместимое объектное хранилище, служит основным репозиторием для:
- хранения артефактов моделей (например, GNN, PPO),
- резервного копирования сервисов и метаданных.

Обеспечивает высокую доступность и интеграцию с Kubernetes через StatefulSet.

---

### Глава 7: Платформа данных: управление информацией

#### 7.1. Strimzi Kafka Operator

**Strimzi** автоматизирует полное управление жизненным циклом Apache Kafka в среде Kubernetes, включая развертывание, обновления, настройку тем, шифрование и мониторинг. Интеграция достигается декларативно через пользовательские ресурсы, такие как `KafkaUser`, `KafkaTopic` и `KafkaConnect`.

#### 7.2. ArangoDB: мультимодельная база данных

ArangoDB — это мультимодельная база данных, которая нативно интегрирует модели данных документов и графов в одном движке:
- **Документы**: используются для хранения исторических свечей и событий, обеспечивая гибкость и масштабируемость.
- **Графы**: применяются для описания сложных взаимосвязей между активами и торговыми операциями, что критически важно для функционирования графовых нейронных сетей (GNN).

#### 7.3. PostgreSQL (Zalando Operator)

**Zalando Operator** управляет развертыванием и работой кластеров PostgreSQL с высокой доступностью, автоматическим резервным копированием и механизмами аварийного переключения. Это решение используется для хранения структурированных реляционных данных, включая таблицы рентабельности инвестиций (ROI), журналы действий агентов и метаданные экспериментов.

#### 7.4. Автомасштабирование с помощью KEDA

**KEDA** (Kubernetes Event-driven Autoscaling) обеспечивает динамическое, событийно-ориентированное масштабирование модулей-потребителей на основе отставания сообщений в Apache Kafka. Это обеспечивает оптимальную адаптацию к изменяющимся рабочим нагрузкам без ручного вмешательства, что оптимизирует использование ресурсов, снижает эксплуатационные расходы и минимизирует задержки обработки.

#### 7.5. Kafka UI

**Kafka UI**, веб-интерфейс от `provectuslabs`, предлагает интуитивно понятную визуальную плоскость управления для управления темами, группами потребителей, пользователями и сообщениями в Apache Kafka.

Параметры:
- Доступ по адресу `https://kafka-ui.dmz.home`
- Интеграция через SASL_SSL (SCRAM-SHA-512)
- Подключение к кластеру `k3`
- Работает на `k2w-7`, 1 реплика

---

### Глава 8: Мониторинг и наблюдаемость: комплексный контроль системы

Для обеспечения стабильной работы и быстрого реагирования на инциденты StreamForge использует комплексный стек наблюдаемости.

#### 8.1. Метрики: Prometheus, NodeExporter, cAdvisor

- **Prometheus** — основная база данных временных рядов для сбора и хранения системных и прикладных метрик.
- **cAdvisor** — инструмент для мониторинга ресурсов и производительности контейнеров.
- **NodeExporter** — экспортер для метрик операционной системы и хоста.

Компоненты:
- kube-prometheus-stack `v71.1.0`
- TLS + Ingress для Prometheus (`prometheus.dmz.home`) и Grafana (`grafana.dmz.home`)
- Постоянные тома: Prometheus — 20Gi, Grafana — 1Gi

#### 8.2. Журналы: Fluent-bit, Elasticsearch, Kibana

Централизованный конвейер журналирования на основе стека **EFK** (Elasticsearch, Fluent-bit, Kibana) реализован для агрегации, маршрутизации и анализа журналов в масштабе всей системы:

- **Fluent-bit** применяет фильтр Lua для динамического создания индексов на основе тегов (например, `internal-myapp-2025.08.07`), обеспечивая гибкость в индексации журналов.
- **Elasticsearch** обеспечивает полнотекстовый поиск, агрегацию и хранение журналов.
- **Kibana** визуализирует журналы, предлагая удобный интерфейс для анализа по тегам, индексам и временным диапазонам.

#### 8.3. Grafana и Alertmanager

- **Grafana** — основная платформа для визуализации данных, интегрированная с Prometheus, Elasticsearch и PostgreSQL для предоставления единого представления системных метрик и журналов.
- **Alertmanager** — управляет маршрутизацией, группировкой и отправкой оповещений по электронной почте и в Telegram на основе предопределенных правил.

---

### Глава 9: Автоматизация и GitOps: оптимизация процессов развертывания

StreamForge управляется с помощью строгой методологии GitOps, которая автоматизирует и оптимизирует развертывание и управление инфраструктурой, тем самым минимизируя ручное вмешательство и повышая надежность системы.

#### 9.1. GitLab Runner

Конвейеры CI/CD работают на базе GitLab CI, используя `kaniko` для безопасной сборки образов контейнеров без демона непосредственно в кластере Kubernetes. Для оптимизации времени сборки и обеспечения согласованности в средах разработки, тестирования и производства используется **единый базовый образ**. Этот образ, созданный из `platform/Dockerfile`, предварительно устанавливает общие зависимости Python, включая все необходимые тестовые фреймворки и библиотеки, и интегрирует библиотеку `streamforge_utils` посредством надежной установки wheel.

- Runner работает в исполнителе `kubernetes` с `nodeSelector` на узле `k2w-9` для оптимального распределения ресурсов.
- **Процессы сборки Kaniko оптимизированы** за счет использования корневого каталога проекта в качестве контекста сборки и использования явного кэширования слоев образа (`--cache=true`) для значительного ускорения последующих сборок.
- Конфигурация CI/CD разделена на общие шаблоны (`.build_python_service`) и конкретные конвейеры для каждого сервиса, обеспечивая модульность и возможность повторного использования.

##### 9.1.1. Runner: особенности конфигурации

- Привилегированные права
- ServiceAccount: `full-access-sa`
- Пулы: `runner-home`, `docker-config`, `home-certificates`
- Репозиторий: `https://gitlab.dmz.home/`

##### 9.1.2. Структура конвейера

- `setup` → `build` → `test` → `deploy`
- Используются файлы include с путями к сервисам
- Повторно используемые шаблоны `.gitlab/ci-templates/`

##### 9.1.3. Интеграция и модульность

Каждый сервис (например, `dummy-service`) использует переменные `SERVICE_NAME`, `SERVICE_PATH` и расширяет общий шаблон.

#### 9.2. ArgoCD

**ArgoCD** — это декларативный движок GitOps, отвечающий за автоматизированное управление состоянием кластера Kubernetes на основе репозитория Git. Он обеспечивает:

- **Единый источник истины:** Репозиторий `iac_kubeadm` (`gitlab.dmz.home`) служит единым источником истины для конфигурации кластера.
- **Поддержка TLS:** Безопасная связь с GitLab обеспечивается через TLS.
- **Веб-доступ:** Доступ к пользовательскому интерфейсу ArgoCD доступен по адресу `argocd.dmz.home`.

- **Контроль версий:** Все компоненты инфраструктуры находятся под контролем версий, что упрощает отслеживание изменений и откат к предыдущим состояниям.

#### 9.3. Reloader

**Reloader** — это легковесный контроллер, который автоматизирует последовательное обновление модулей при изменении связанных с ними объектов `Secret` или `ConfigMap`. Это гарантирует, что приложения всегда используют последнюю конфигурацию без ручного вмешательства.

---

### Глава 10: Безопасность и дополнительные возможности

#### 10.1. HashiCorp Vault

**HashiCorp Vault** интегрирован с `Vault CSI Driver` для облегчения безопасной и динамической инъекции временных секретов в модули Kubernetes, предотвращая их постоянное хранение в кластере.

#### 10.2. Keycloak

**Keycloak** служит центральным решением для управления идентификацией и доступом (IAM) для всех сервисов платформы. Он поддерживает стандарты SSO (Single Sign-On) и OpenID Connect, интегрируясь с Grafana, Kibana и ArgoCD для централизованного управления пользователями и разрешениями.

#### 10.3. NVIDIA GPU Operator

**NVIDIA GPU Operator** автоматизирует управление ресурсами NVIDIA GPU в кластере Kubernetes, включая установку и настройку драйверов, тем самым абстрагируя сложности оборудования.

- Версия: `v24.9.2`
- Поддержка обучения GNN: предоставляет необходимую инфраструктуру для эффективного обучения графовых нейронных сетей.
- Простое обновление через Helm: упрощает процесс обновления и управления оператором.

#### 10.4. Другие утилиты

- `kubed` — контроллер для синхронизации ресурсов Kubernetes (например, секретов, ConfigMaps) между пространствами имен, обеспечивая согласованность конфигурации.
- `Mailrelay` — централизованный SMTP-ретранслятор для отправки уведомлений от различных компонентов системы, включая Alertmanager, CronJobs и конвейеры CI/CD.