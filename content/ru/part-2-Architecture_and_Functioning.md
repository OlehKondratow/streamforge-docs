+++
date = '2025-08-25T10:02:00+02:00'
draft = false
title = 'Инфраструктурная платформа и технологический стек'
weight = 2
+++

# Часть III: Инфраструктурная платформа и технологический стек

### **Глава 5: Основы платформы: Kubernetes и виртуализация**

Приложение StreamForge разворачивается на базе мощной и гибкой инфраструктурной платформы, построенной на основе Kubernetes и современных cloud-native инструментов.

#### **5.1. Физический уровень: Гипервизор Proxmox VE**

В качестве основы для виртуализации используется `Proxmox VE`. Это позволяет эффективно управлять физическими ресурсами, создавать виртуальные машины для узлов Kubernetes и обеспечивать изоляцию и гибкость в распределении вычислительных мощностей.

#### **5.2. Развертывание кластера: Kubespray**

Кластер Kubernetes разворачивается с помощью `Kubespray`. Этот инструмент обеспечивает автоматизированное и воспроизводимое создание production-ready кластеров, что значительно упрощает первоначальную настройку и последующие обновления.

#### **5.3. Сетевая инфраструктура**

*   **`kube-vip` для High Availability Control Plane:** Для обеспечения высокой доступности управляющих узлов (control plane) используется `kube-vip`. Он предоставляет виртуальный IP-адрес для Kubernetes API-сервера, что позволяет избежать единой точки отказа.
*   **`MetalLB` для Service Type `LoadBalancer`:** В "bare-metal" окружении `MetalLB` позволяет использовать стандартный тип сервиса `LoadBalancer`, предоставляя внешние IP-адреса для доступа к сервисам извне кластера.

#### **5.4. Ingress и Gateway API**

Для управления внешним трафиком и его маршрутизации к внутренним сервисам используются два ведущих Ingress-контроллера: `Traefik` и `ingress-nginx`. `Traefik` является предпочтительным решением, в том числе благодаря его поддержке нового стандарта **Gateway API**, который предлагает более гибкую и ролевую модель управления трафиком. `ingress-nginx` (версия `4.12.1`, приложение `1.12.1`) также развернут со стандартными настройками и служит в качестве альтернативного или дополнительного Ingress-контроллера.

**Конфигурация Traefik (версия `36.1.0`, приложение `v3.4.1`):**

*   **Точки входа (EntryPoints):**
    *   `web`: HTTP на порту `80`, автоматически перенаправляется на `websecure` (HTTPS).
    *   `websecure`: HTTPS на порту `443` с включенным TLS.
    *   `ssh`: TCP на порту `2222`.
    *   `kafka`: TCP на порту `9094`.
*   **Панель мониторинга (Dashboard):** Включена и доступна через Ingress по адресу `traefik.dmz.home/dashboard`. Для нее автоматически выпускается TLS-сертификат (`traefik-dashboard-tls`) с помощью `cert-manager`.
*   **Управление сертификатами:** Используется `certificatesResolvers` с `default` ACME-челленджем для автоматического получения TLS-сертификатов. Хранилище для ACME-данных (`acme.json`) находится в персистентном томе.
*   **Персистентность:** Включена персистентность с `PersistentVolumeClaim` размером `1Gi` на базе `nfs-client` для хранения данных Traefik (например, ACME-сертификатов).
*   **Тип сервиса:** `LoadBalancer` с фиксированным IP-адресом `192.168.1.153` для внешнего доступа.
*   **Провайдеры:** Включены `kubernetesCRD` и `kubernetesIngress` для обнаружения и маршрутизации трафика к сервисам, определенным через Ingress-ресурсы и кастомные ресурсы Traefik.

#### **5.5. Управление DNS и TLS**

*   **`Technitium DNS Server`:** Используется как локальный DNS-сервер для разрешения имен в домене `dmz.home`, что упрощает доступ к сервисам по человекочитаемым именам.
*   **`cert-manager`:** Автоматизирует процесс управления TLS-сертификатами. В связке с локальным `ClusterIssuer` он обеспечивает автоматическую выдачу и ротацию сертификатов для всех Ingress-ресурсов, гарантируя безопасное `HTTPS`-соединение.

### **Глава 6: Система хранения данных (Storage)**

Надежное и производительное хранилище является критически важным компонентом платформы StreamForge. Для различных типов данных и сценариев использования применяются специализированные решения.

#### **6.1. Обзор Storage-решений**

*   **`Linstor Piraeus` (RWO - ReadWriteOnce):** Это решение используется для предоставления высокопроизводительных блочных хранилищ. Оно идеально подходит для stateful-приложений, требующих низкой задержки и высокой пропускной способности, таких как базы данных (`ArangoDB`, `PostgreSQL`).
*   **`GlusterFS` и `NFS Subdir External Provisioner` (RWX - ReadWriteMany):** Эти системы предоставляют файловые хранилища с совместным доступом. Они используются для сценариев, где несколько подов должны одновременно читать и записывать данные в один и тот же том, например, для хранения общих конфигураций или лог-файлов.

    **`NFS Subdir External Provisioner` (версия `4.0.18`, приложение `4.0.2`):**
    *   **Сервер NFS:** `192.168.1.6`
    *   **Путь NFS:** `/data0/k2`
    *   **Назначение:** Используется для динамического выделения персистентных томов (PV) на основе существующего NFS-сервера, обеспечивая доступ `ReadWriteMany` (RWX) для нескольких подов. Это критически важно для общих файловых систем, таких как домашние директории JupyterHub или общие проектные данные.

#### **6.2. Объектное хранилище Minio**

`Minio` предоставляет S3-совместимое объектное хранилище внутри кластера. В StreamForge оно выполняет две ключевые функции:
1.  **Хранение артефактов машинного обучения:** `gnn-trainer` сохраняет в Minio обученные модели, их веса, чекпоинты и метрики обучения. Это обеспечивает версионирование и долгосрочное хранение результатов экспериментов.
2.  **Хранение бэкапов:** Используется для хранения резервных копий баз данных и других критически важных компонентов системы.

### **Глава 7: Платформа данных (Data Platform)**

Платформа данных является ядром StreamForge, обеспечивая сбор, передачу, хранение и обработку информации.

#### **7.1. `Strimzi Kafka Operator` как ядро системы обмена сообщениями**

`Strimzi` используется для декларативного управления кластерами Apache Kafka в Kubernetes. Он автоматизирует сложные задачи, такие как развертывание, конфигурация, управление топиками и пользователями, а также обеспечивает высокую доступность и отказоустойчивость брокера сообщений.

#### **7.2. Мультимодельная база данных `ArangoDB`**

`ArangoDB` выбрана в качестве основной базы данных благодаря своей мультимодельной природе. Она позволяет хранить данные как в виде документов (JSON), так и в виде графов, что идеально подходит для задач StreamForge:
*   **Документная модель:** Используется для хранения "плоских" данных, таких как исторические свечи, сделки и состояние очередей `queue-manager`.
*   **Графовая модель:** Является ключевой для аналитического слоя. `graph-builder` создает графы рыночных взаимосвязей, которые затем используются `gnn-trainer` для обучения моделей.

#### **7.3. Реляционная база данных `PostgreSQL` (Zalando Operator)**

Для хранения структурированных служебных данных, требующих строгой консистентности и транзакционности (например, конфигурации пользователей, метаданные), используется `PostgreSQL`. Управление кластером PostgreSQL автоматизировано с помощью оператора от Zalando, который обеспечивает высокую доступность и простоту управления.

#### **7.4. Автомасштабирование на основе событий с `KEDA`**

`KEDA` (Kubernetes Event-driven Autoscaling) позволяет автоматически масштабировать количество подов (воркеров) на основе внешних событий. В контексте StreamForge, KEDA будет использоваться для мониторинга длины очередей (lag) в топиках Kafka. Если количество необработанных сообщений в топике превышает заданный порог, KEDA автоматически увеличит количество подов-консьюмеров (например, `arango-connector`), а при уменьшении нагрузки — сократит их, оптимизируя использование ресурсов.

### **Глава 8: Наблюдаемость (Observability)**

Полноценная система наблюдаемости является краеугольным камнем для эксплуатации и отладки распределенной системы, такой как StreamForge.

#### **8.1. Стек метрик: `Prometheus`, `cAdvisor`, `NodeExporter`**

`Prometheus` используется для сбора и хранения временных рядов (метрик). `NodeExporter` собирает метрики с хостовых машин (CPU, RAM, disk), а `cAdvisor` — с контейнеров. Каждый микросервис StreamForge также предоставляет собственные метрики (например, `records_written_total`, `queue_requests_total`), которые автоматически обнаруживаются и собираются Prometheus.

**Ключевые особенности конфигурации:**

*   **Версия:** `kube-prometheus-stack-71.1.0` (приложение `v0.82.0`).
*   **Prometheus:**
    *   **Хранилище:** Использует `PersistentVolumeClaim` размером `20Gi` на базе `nfs-client` для хранения данных временных рядов.
    *   **Доступ:** Доступен через Ingress по адресу `prometheus.dmz.home` с использованием `nginx` Ingress-контроллера и TLS-сертификата (`prometheus-tls`).
*   **Alertmanager:**
    *   **Хранилище:** Использует `PersistentVolumeClaim` размером `500Mi` на базе `nfs-client` для хранения данных.
*   **Grafana:**
    *   **Хранилище:** Включена персистентность с `PersistentVolumeClaim` размером `1Gi` на базе `nfs-client`.
    *   **Доступ:** Доступен через Ingress по адресу `grafana.dmz.home` с использованием `nginx` Ingress-контроллера и TLS-сертификата (`grafana-tls`).
*   **Общие настройки:** Для всех Ingress-ресурсов используется `cert-manager` с `homelab-ca-issuer` для автоматического выпуска TLS-сертификатов.

#### **8.2. Стек логирования: `Fluent-bit`, `Elasticsearch`, `Kibana`**

Система логирования в StreamForge — это комплексное решение, обеспечивающее не только сбор и хранение, но и удобство отладки и анализа логов. Платформа использует гибридный подход, собирая как структурированные логи приложений, так и системные логи с узлов кластера.

**Ключевые компоненты и версии:**
*   **Elasticsearch:** `v8.12.0`
*   **Kibana:** `v8.12.0`
*   **Fluent-bit:** `v4.0.0-amd64`

**Архитектура сбора логов:**

Платформа разделяет сбор логов на два потока:

**1. Логи приложений (прямая пересылка):**

Этот механизм предназначен для микросервисов StreamForge и обеспечивает максимальную гибкость и обогащение данных.

*   **Метод:** Приложения, используя стандартные библиотеки логирования (например, `fluent-logger` для Python), отправляют свои логи по сети напрямую на централизованный сервис-агрегатор `fluent-bit` через протокол `forward` на порт `24224`.
*   **Динамическая генерация индексов:** Это ключевая особенность конфигурации. С помощью специального **Lua-скрипта** `fluent-bit` анализирует **тег** каждого входящего лога (например, `internal.my-app`). На основе этого тега и временной метки он динамически формирует имя индекса в Elasticsearch в формате `prefix-app-YYYY.MM.DD` (например, `internal-my-app-2025.08.06`). Такой подход критически важен для эффективного управления данными: он упрощает поиск, оптимизирует производительность и позволяет легко настраивать политики хранения.

**2. Системные и инфраструктурные логи (сбор из файлов):**

В дополнение к логам приложений, `fluent-bit` (развернутый как `DaemonSet`) также собирает стандартные логи с каждого узла кластера.
*   **Источники:** Конфигурация включает сбор логов из:
    *   `/var/log/syslog` (системные сообщения)
    *   `/var/log/nginx/access.log` (логи доступа Nginx)
    *   `/var/log/auth.log` (логи аутентификации)
*   **HTTP-вход:** Также открыт HTTP-вход на порту `8888` для приема логов от внешних систем.

**Конфигурация Elasticsearch и хранение данных:**

*   **Развертывание:** Elasticsearch работает как `StatefulSet` с одной репликой (`single-node`), что не обеспечивает высокой доступности, но подходит для текущих задач.
*   **Ресурсы:** Поду выделено 2-4Gi памяти и 1-2 ядра CPU.
*   **Хранилище:** Для данных используется `PersistentVolumeClaim` размером `10Gi` на базе `nfs-client`.
*   **Политика хранения (ILM):** Настроена политика жизненного цикла индексов (`ilmPolicy`) под названием `log-retention-30d`:
    *   **Rollover:** Новый индекс создается ежедневно (`rolloverAfter: 1d`) или когда размер текущего достигает `2gb`.
    *   **Удаление:** Данные автоматически удаляются через 30 дней (`deleteAfter: 30d`).
*   **Доступ:** Доступ к Kibana для анализа логов осуществляется по адресу `kibana.dmz.home` и защищен TLS-сертификатом.

**Примеры реализации (логи приложений):**

**1. Отправка логов из приложения (Python):**
Приложение должно использовать `fluent-logger` для отправки структурированных логов с правильным тегом.

```python
# Пример из test-logger-script.yaml
from fluent import sender
import time
import random
import json

APP_NAME = "my-pod-app"

# Настраиваем логгер для отправки на сервис fluent-bit
logger = sender.FluentSender(
    tag='internal.' + APP_NAME, # Важно: тег определяет будущий индекс!
    host='fluent-bit-service.logging.svc.cluster.local',
    port=24224
)

# Генерируем и отправляем структурированный лог
log_record = {
    'message': 'User logged in successfully',
    'level': 'INFO',
    'user_id': 12345
}
logger.emit('log', log_record)
```

**2. Обработка и создание индекса (Lua в Fluent-bit):**
Этот Lua-скрипт, вызываемый для каждой записи, извлекает части из тега и создает поле `log_index`, которое Elasticsearch использует для именования индекса.

```lua
# Пример из fluent-bit-config.yaml (set_index.lua)
function cb_set_index(tag, timestamp, record)
    local t = os.time()
    if timestamp and type(timestamp) == "table" and timestamp[1] > 0 then
        t = timestamp[1]
    end

    local prefix = "unknown"
    local app = "unknown"

    -- Разбираем тег, например, "internal.my-pod-app"
    local parts = {}
    for part in string.gmatch(tag, "([^.]+)") do
        table.insert(parts, part)
    end
    if #parts >= 2 then
        prefix = parts[1]  -- "internal"
        app = parts[2]     -- "my-pod-app"
    end

    -- Создаем имя индекса на основе даты
    local date = os.date("%Y.%m.%d", t)
    -- Добавляем новое поле в запись лога
    record["log_index"] = prefix .. "-" .. app .. "-" .. date -- получится "internal-my-pod-app-2025.08.06"
    return 1, timestamp, record
end
```

**Инструменты для отладки и тестирования:**

Для обеспечения надежности и удобства разработки в систему встроены специальные инструменты:

*   **`test-logger-script`:** Это тестовый Python-скрипт, который использует `fluent-logger` для генерации и отправки логов с заданным тегом напрямую в `fluent-bit`. Он позволяет разработчикам легко проверить весь конвейер логирования от отправки до появления записи в Kibana.
*   **`fluentbit-tailon`:** Это специальный отладочный `Deployment`, который запускает в одном поде два контейнера: `fluent-bit` и `tailon` (легковесный веб-интерфейс для просмотра логов). Этот `fluent-bit` принимает логи по сети и одновременно пишет их в локальный файл, который `tailon` тут же отображает. Это дает возможность в реальном времени видеть "сырой" поток логов, поступающий в систему, что бесценно для быстрой отладки без необходимости ждать индексации в Elasticsearch.

#### **8.3. Визуализация и алертинг: `Grafana`, `Alertmanager`**

`Grafana` служит единой точкой для визуализации как метрик из Prometheus, так и логов из Elasticsearch. Она используется для создания дашбордов, отображающих состояние системы в реальном времени. `Alertmanager` интегрирован с Prometheus и отвечает за дедупликацию, группировку и маршрутизацию алертов, отправляя уведомления в Telegram при возникновении критических ситуаций.

### **Глава 9: CI/CD и GitOps**

Автоматизация сборки, тестирования и развертывания является основой для быстрой и надежной доставки изменений.

#### **9.1. `GitLab Runner` как исполнитель пайплайнов**

`GitLab Runner` является ключевым компонентом CI/CD, отвечающим за выполнение задач (jobs), определенных в `.gitlab-ci.yml`. В проекте используется `gitlab-runner` версии `bleeding` с исполнителем (executor) типа `kubernetes`, что обеспечивает глубокую интеграцию с кластером. Для сборки Docker-образов без использования Docker-in-Docker применяется `Kaniko`.

##### **9.1.1. Конфигурация и особенности исполнителя (Runner)**

**Общие настройки Runner:**

*   **Исполнитель (Executor):** `kubernetes`. Для каждой CI/CD задачи Runner создает отдельный Pod в неймспейсе `gitlab`, что гарантирует изоляцию сборок и тестов.
*   **Привязка к узлу:** Runner настроен на запуск подов исключительно на узле `k2w-9` с помощью `nodeSelector`.
*   **Права доступа:** Runner использует предварительно созданный `ServiceAccount` с именем `full-access-sa` и работает в привилегированном режиме (`privileged = true`). Это предоставляет подам с задачами широкие права в кластере, необходимые для сборки образов и развертывания приложений.
*   **Образ по умолчанию:** Для выполнения задач по умолчанию используется образ `ubuntu:22.04`.
*   **Ресурсы:** Для каждого пода с задачей установлены следующие лимиты и запросы:
    *   **Запрос:** 100m CPU, 128Mi RAM.
    *   **Лимит:** 500m CPU, 512Mi RAM.
*   **Кэширование:** Для ускорения CI/CD пайплайнов используется распределенное кэширование на базе S3.
    *   **Сервер:** `minio.dmz.home` (внутренний Minio).
    *   **Бакет:** `runner-cache`.
    *   **Безопасность:** Соединение с Minio осуществляется по HTTP (`Insecure = true`).
*   **Интеграция с Docker Registry:** Секрет `regcred` монтируется в поды как `/kaniko/.docker/config.json`, обеспечивая бесшовную аутентификацию для push- и pull-операций с приватными Docker-репозиториями.
*   **TLS:** Секрет `home-certificates` монтируется в `/kaniko/ssl/certs`, что позволяет `kaniko` и другим инструментам доверять внутренним TLS-сертификатам.

**Специфическая конфигурация `stf-runner` (k2m-runner):**

*   **Имя:** `k2m-runner` (отображается как `stf-runner` в `helm list`).
*   **Версия:** `0.79.0` (приложение `18.2.0`).
*   **URL GitLab:** `https://gitlab.dmz.home/`
*   **Пространство имен Kubernetes:** `gitlab`
*   **Таймаут опроса:** 300 секунд.
*   **Монтирование томов:**
    *   `docker-config` (из секрета `regcred`) монтируется в `/kaniko/.docker` для аутентификации Docker.
    *   `home-certificates` (из секрета `home-certificates`) монтируется в `/kaniko/ssl/certs` для доверия к внутренним TLS-сертификатам.
    *   `runner-home` (PVC `gitlab-runner-home`) монтируется в `/home/gitlab-runner` для персистентного хранения данных Runner.

##### **9.1.2. Структура CI/CD пайплайна**

CI/CD пайплайн проекта StreamForge организован в несколько последовательных стадий (`stages`), каждая из которых выполняет определенный набор задач (`jobs`).

**Стадии пайплайна:**
*   **`setup`**: На этой стадии выполняются подготовительные работы, такие как применение Kubernetes RBAC манифестов (Service Accounts, Roles, RoleBindings), чтобы обеспечить необходимые разрешения для последующих операций развертывания.
*   **`build`**: На этой стадии происходит сборка Docker-образов для всех микросервисов и базовых образов. Для сборки образов используется `Kaniko`, что позволяет выполнять сборку внутри кластера Kubernetes без необходимости запуска Docker-демона.
*   **`test`**: Эта стадия предназначена для запуска автоматизированных тестов (юнит-тестов, интеграционных тестов) для проверки функциональности и стабильности кода.
*   **`deploy`**: На этой стадии происходит развертывание собранных Docker-образов в Kubernetes кластер. Для взаимодействия с кластером используется `kubectl`.

**Как запускаются job'ы:**
Каждый job в пайплайне имеет определенные правила (`rules`), которые определяют, когда он должен быть запущен. Job'ы могут запускаться автоматически при изменениях в определенных файлах (например, при изменении кода сервиса или его `Dockerfile`), а также могут быть настроены на ручной запуск (`when: manual`) через интерфейс GitLab CI. Это обеспечивает гибкость и контроль над процессом развертывания.

##### **9.1.3. Детализация конфигурации пайплайнов**

Конфигурация CI/CD пайплайнов в StreamForge построена на принципах модульности и переиспользования кода с использованием возможностей GitLab CI `include` и `extends`.

**Основной файл `.gitlab-ci.yml`:**

Этот файл является точкой входа для всего пайплайна. Он определяет общие стадии (`stages`) и включает (`include`) конфигурации для отдельных сервисов и компонентов платформы. Это позволяет держать основной файл чистым и легко управляемым.

Пример `/.gitlab-ci.yml`:
```yaml
stages:
  - setup
  - build
  - test
  - deploy

include:
  - '/services/queue-manager/.gitlab-ci.yml'
  - '/services/loader-api-trades/.gitlab-ci.yml'
  - '/services/loader-api-candles/.gitlab-ci.yml'
  - '/services/arango-connector/.gitlab-ci.yml'
  - '/services/dummy-service/.gitlab-ci.yml'
  - 'platform/.gitlab-ci.yml' # Включаем конфигурацию для платформы (базовый образ, RBAC)
```

**Шаблоны CI/CD (`.gitlab/ci-templates/`):**

Для обеспечения единообразия и переиспользования логики сборки и тестирования, используются общие шаблоны. Например, `Python-Service.gitlab-ci.yml` содержит общую конфигурацию для сборки Docker-образов Python-сервисов.

Пример `/.gitlab/ci-templates/Python-Service.gitlab-ci.yml`:
```yaml
.build_python_service:
  stage: build
  image: gcr.io/kaniko-project/executor:debug
  script:
    - SERVICE_VERSION=$(cat $CI_PROJECT_DIR/$SERVICE_PATH/VERSION)
    - /kaniko/executor
      --context $CI_PROJECT_DIR/$SERVICE_PATH
      --dockerfile Dockerfile
      --destination $CI_REGISTRY_IMAGE/$SERVICE_NAME:$SERVICE_VERSION
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - $SERVICE_PATH/**/*
        - libs/**/*
    - if: '$CI_COMMIT_BRANCH == "main"'
      changes:
        - $SERVICE_PATH/**/*
        - libs/**/*
    - when: manual
      allow_failure: false
```

**Конфигурация для отдельных сервисов (`services/<service-name>/.gitlab-ci.yml`):**

Каждый микросервис имеет свой собственный `.gitlab-ci.yml` файл, который включает общий шаблон и расширяет его, предоставляя специфичные для сервиса переменные.

Пример `services/dummy-service/.gitlab-ci.yml`:
```yaml
include:
  - project: 'kinga/stream-forge'
    ref: main
    file: '/.gitlab/ci-templates/Python-Service.gitlab-ci.yml'

build-dummy-service:
  extends: .build_python_service
  variables:
    SERVICE_NAME: dummy-service
    SERVICE_PATH: services/dummy-service

deploy-dummy-service:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl apply -f $CI_PROJECT_DIR/services/dummy-service/k8s/dummy-service-deployment.yaml
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success
```

**Конфигурация для компонентов платформы (`platform/.gitlab-ci.yml`):**

Аналогично сервисам, компоненты платформы (например, сборка базового образа, применение RBAC) имеют свои собственные конфигурационные файлы.

Пример `platform/.gitlab-ci.yml`:
```yaml
include:
  - project: 'kinga/stream-forge'
    ref: main
    file: '/.gitlab/ci-templates/Python-Service.gitlab-ci.yml' # Используем тот же шаблон для сборки базового образа

build-base-image:
  extends: .build_python_service
  variables:
    SERVICE_NAME: base
    SERVICE_PATH: platform # Указываем путь к Dockerfile и VERSION для базового образа

apply-rbac:
  stage: setup
  image: bitnami/kubectl:latest
  script:
    - kubectl apply -f $CI_PROJECT_DIR/input/cred-kafka-yaml/full-access-sa.yaml
    - kubectl apply -f $CI_PROJECT_DIR/input/cred-kafka-yaml/full-access-sa-binding.yaml
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      changes:
        - input/cred-kafka-yaml/full-access-sa.yaml
        - input/cred-kafka-yaml/full-access-sa-binding.yaml
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - input/cred-kafka-yaml/full-access-sa.yaml
        - input/cred-kafka-yaml/full-access-sa-binding.yaml
    - when: manual
      allow_failure: false
```

Такая структура обеспечивает гибкость, переиспользование и легкую масштабируемость CI/CD пайплайнов в проекте StreamForge.


#### **9.2. `ArgoCD` для декларативного управления состоянием кластера**

`ArgoCD` реализует подход GitOps, непрерывно синхронизируя состояние кластера с декларативным описанием, хранящимся в Git-репозитории. Это гарантирует, что кластер всегда находится в ожидаемом состоянии, и упрощает откат к предыдущим версиям.

**Ключевые особенности конфигурации:**

*   **Репозиторий GitOps:** Платформа предварительно сконфигурирована для работы с Git-репозиторием `iac_kubeadm` (`https://gitlab.dmz.home/infra-a-cod/iac_kubeadm.git`), который служит единым источником правды для состояния кластера.
*   **Доступ к серверу:** В текущей конфигурации (`server.insecure: true`) ArgoCD API-сервер доступен без шифрования TLS. Доступ к веб-интерфейсу осуществляется через домен `argocd.dmz.home`, однако Ingress-ресурс для него управляется отдельно (`server.ingress.enabled: false`).
*   **Отказоустойчивость:** Все ключевые компоненты ArgoCD (`controller`, `repoServer`, `server`) работают в одном экземпляре (`replicas: 1`), что не обеспечивает высокой доступности.
*   **Управление CRD:** Пользовательские определения ресурсов (CRD), устанавливаемые ArgoCD, не сохраняются при удалении чарта (`crds.keep: false`), что означает полную очистку ресурсов при деинсталляции.
*   **Интеграция с GitLab:** В конфигурацию добавлен TLS-сертификат для `gitlab.dmz.home`, что позволяет ArgoCD безопасно подключаться к репозиториям, размещенным на внутреннем сервере GitLab.

#### **9.3. `Reloader` для автоматического обновления приложений**

`Reloader` следит за изменениями в `ConfigMap` и `Secret`. Когда связанный с `Deployment` или `StatefulSet` конфигурационный файл или секрет обновляется, `Reloader` автоматически выполняет rolling restart соответствующего приложения, чтобы оно подхватило новые настройки.

### **Глава 10: Безопасность и специализированные сервисы**

#### **10.1. Управление секретами с `HashiCorp Vault` и `Vault CSI Driver`**

Для безопасного хранения и управления секретами (пароли, API-ключи, токены) используется `HashiCorp Vault`. Интеграция с Kubernetes осуществляется через `Vault CSI Driver`, который позволяет подам получать секреты, монтируя их как временные тома. Это устраняет необходимость хранить секреты в виде Kubernetes `Secret` объектов и обеспечивает централизованное управление с ротацией и аудитом.

#### **10.2. Аутентификация и авторизация с `Keycloak`**

`Keycloak` выступает в роли централизованного сервера идентификации и управления доступом. Он обеспечивает Single Sign-On (SSO) для всех веб-интерфейсов платформы, включая `Grafana`, `Kibana`, `ArgoCD` и будущий UI самого StreamForge.

#### **10.3. Ускорение вычислений с `NVIDIA GPU Operator`**

Для задач машинного обучения, требующих значительных вычислительных ресурсов, используется `NVIDIA GPU Operator`. Он автоматизирует управление жизненным циклом программного обеспечения, необходимого для использования GPU от NVIDIA в среде Kubernetes. Это включает в себя установку драйверов, плагинов устройств и других компонентов, что критически важно для эффективного обучения GNN-моделей в `gnn-trainer`.

**Ключевые особенности:**

*   **Версия:** `v24.9.2`
*   **Конфигурация:** Развертывание `gpu-operator` осуществляется с использованием стандартных настроек Helm-чарта. Никаких пользовательских параметров (`USER-SUPPLIED VALUES: null`) не применяется, что обеспечивает простоту обновления и соответствие официальным рекомендациям NVIDIA.
*   **Функциональность:** Оператор автоматически обнаруживает наличие GPU на узлах кластера и устанавливает все необходимые компоненты, делая их доступными для подов через стандартные механизмы запроса ресурсов Kubernetes (например, `nvidia.com/gpu: 1`).

#### **10.4. Прочие утилиты**

*   **`kubed`:** Используется для синхронизации ресурсов, таких как `ConfigMap` и `Secret`, между различными неймспейсами, что упрощает управление общей конфигурацией.
*   **`Mailrelay`:** Выступает в роли централизованного SMTP-шлюза для отправки почтовых уведомлений, например, из `Alertmanager`.
