+++
date = '2025-08-24T20:22:28+02:00'
draft = true
title = 'Архитектура и функционирование'
weight = 2
+++
## Часть II: Архитектура и функционирование

### Глава 2: Высокоуровневая архитектура

#### 2.1. Основные архитектурные принципы

Архитектура StreamForge разработана на основе нескольких ключевых принципов для создания гибкой, надежной и масштабируемой платформы:

1.  **Разделение через событийно-ориентированную модель:**
    В основе StreamForge лежит событийно-ориентированная модель, в которой Apache Kafka служит центральной шиной сообщений. Это коренным образом разделяет сервисы друг от друга. `queue-manager` инициирует рабочий процесс (например, загрузку данных BTC), и соответствующие микросервисы (например, `loader-producer`) реагируют на эти события. Эта парадигма обеспечивает независимую разработку, развертывание и масштабирование каждого микросервиса, способствуя отказоустойчивости и гибкости всей системы.

2.  **Масштабируемость:**
    Платформа предназначена для динамической адаптации к нагрузке. Приложения без сохранения состояния, такие как `loader-*` и `arango-connector`, развертываются как эфемерные задания Kubernetes. Такая конструкция позволяет выполнять задачи по требованию в параллельном режиме, обеспечивая присущую ей масштабируемость. В будущих итерациях будет интегрирована **KEDA (Kubernetes Event-driven Autoscaling)** для обеспечения проактивного масштабирования потребителей на основе отставаний в темах Kafka, что еще больше оптимизирует использование ресурсов.

3.  **Наблюдаемость:**
    Надежный стек наблюдаемости является неотъемлемой частью архитектуры, обеспечивая глубокое понимание распределенной системы:
    *   **Метрики:** Микросервисы экспортируют метрики в Prometheus, которые затем визуализируются в Grafana. Сюда входят как системные показатели (ЦП, память), так и бизнес-метрики (количество обработанных записей, задержки).
    *   **Ведение журналов:** Централизованный сбор журналов осуществляется с помощью Fluent-bit с последующим анализом и визуализацией в Elasticsearch и Kibana.
    *   **Телеметрия на уровне бизнеса:** Выделенная тема `queue-events` обеспечивает сквозное отслеживание бизнес-процессов. Она фиксирует полный жизненный цикл каждого рабочего процесса, регистрируя переходы состояний от инициации до завершения или ошибки во всех участвующих микросервисах.

#### 2.2. Поток данных в системе

Следующая диаграмма иллюстрирует поток данных для типичного рабочего процесса приема исторических данных в экосистеме StreamForge:

**Пошаговое описание процесса:**
1.  **Инициация рабочего процесса:** Пользователь или автоматизированный процесс инициирует рабочий процесс обработки данных посредством запроса к API `queue-manager`.
2.  **Регистрация состояния:** `queue-manager` регистрирует новый рабочий процесс в ArangoDB, присваивая ему уникальный `queue_id` и начальный статус `pending`.
3.  **Отправка команды:** Команда `start`, содержащая все необходимые параметры задания, публикуется `queue-manager` в теме `queue-control` в Apache Kafka.
4.  **Создание экземпляра задания:** `queue-manager` генерирует необходимые манифесты заданий Kubernetes, которые затем планируются для выполнения, запуская необходимые модули микросервисов (например, `loader-producer`, `arango-connector`).
5.  **Потребление команды:** Вновь созданные микросервисы потребляют команду `start` из темы `queue-control`, которая соответствует их назначенному `queue_id`.
6.  **Прием данных:** Сервис `loader-producer` устанавливает соединение с внешним источником данных (например, Binance API) и начинает извлечение данных.
7.  **Публикация событий:** `loader-producer` сериализует полученные данные в дискретные сообщения и публикует их в выделенной теме данных в Kafka (например, `btc-klines-1m`).
8.  **Отчетность по телеметрии:** На протяжении всего своего жизненного цикла все активные сервисы (`loader-producer`, `arango-connector`) публикуют обновления статуса (например, `loading`, `completed`, `error`) в теме `queue-events`, обеспечивая видимость прогресса в реальном времени.
9.  **Потребление данных для сохранения:** Сервис `arango-connector` подписывается на соответствующую тему данных и потребляет поток событий.
10. **Сохранение данных:** `arango-connector` обрабатывает и сохраняет данные в назначенных коллекциях в базе данных ArangoDB.
11. **Мониторинг и завершение рабочего процесса:** `queue-manager` постоянно отслеживает тему `queue-events`, обновляя статус рабочего процесса в ArangoDB на основе полученной телеметрии. Это обеспечивает полный аудиторский след процесса в реальном времени.

### Глава 3: Apache Kafka как центральный компонент

Apache Kafka является центральной нервной системой архитектуры StreamForge, обеспечивая ключевые преимущества событийно-ориентированной парадигмы:

*   **Разделение и асинхронность:** Сервисы работают с полной автономией. Производители (например, `loader-producer`) публикуют события в Kafka без какого-либо знания или зависимости от потребителей (например, `arango-connector`). Это временное разделение позволяет разрабатывать, развертывать и масштабировать компоненты независимо друг от друга, а также позволяет системе поглощать всплески данных, не затрагивая нижестоящие сервисы.
*   **Отказоустойчивость и долговечность:** Kafka функционирует как распределенный, постоянный журнал. В случае сбоя потребляющего сервиса сообщения безопасно сохраняются в теме. После восстановления сервис может возобновить обработку с последнего известного смещения, гарантируя доставку как минимум один раз и предотвращая потерю данных.
*   **Масштабируемость и расширяемость:** Событийно-ориентированная модель обеспечивает плавное горизонтальное масштабирование. Новые экземпляры сервиса могут быть добавлены в группу потребителей для увеличения пропускной способности обработки. Кроме того, архитектура по своей сути расширяема; новые функции могут быть введены путем развертывания новых микросервисов, которые подписываются на существующие потоки событий, не требуя каких-либо изменений в исходных производителях данных.

Оркестровка и мониторинг StreamForge организованы вокруг двух сервисных тем:

##### Тема `queue-control`
*   **Назначение:** Основной канал для передачи команд от `queue-manager` к сервисам.
*   **Инициатор:** Исключительно `queue-manager`.
*   **Получатели:** Все вычислительные компоненты (`loader-*`, `arango-connector` и другие).
*   **Пример сообщения:**
    ```json
    {
      "command": "start",
      "queue_id": "wf-btcusdt-api_candles_5m-20240801-a1b2c3",
      "target": "loader-producer",
      "symbol": "BTCUSDT",
      "type": "api_candles_5m",
      "time_range": "2024-08-01:2024-08-02",
      "kafka_topic": "wf-btcusdt-api_candles_5m-20240801-a1b2c3-data",
      "collection_name": "btcusdt_api_candles_5m_2024_08_01",
      "telemetry_id": "loader-producer__a1b2c3",
      "image": "registry.dmz.home/streamforge/loader-producer:v0.2.0",
      "timestamp": 1722500000.123
    }
    ```

##### Тема `queue-events`
*   **Назначение:** Канал отчетности о выполнении задач всеми сервисами.
*   **Инициатор:** Все вычислительные компоненты.
*   **Получатели:** `queue-manager`, который отслеживает процесс выполнения для обновления статусов.
*   **Пример сообщения:**
    ```json
    {
      "queue_id": "wf-btcusdt-api_candles_5m-20240801-a1b2c3",
      "producer": "arango-connector__a1b2c3",
      "symbol": "BTCUSDT",
      "type": "api_candles_5m",
      "status": "loading",
      "message": "Saved 15000 records",
      "records_written": 15000,
      "finished": false,
      "timestamp": 1722500125.456
    }
    ```

### Глава 4: Микросервисы

StreamForge — это сложная система, состоящая из специализированных микросервисов, каждый из которых выполняет уникальную и четко определенную функцию.

#### 4.1. `queue-manager`: Движок оркестровки

`queue-manager` — это мозг платформы, отвечающий за сквозную оркестровку рабочих процессов обработки данных. Его основные функции включают:
*   **Управление рабочими процессами:** Управляет полным жизненным циклом рабочего процесса, от запроса API до конечного состояния.
*   **Отслеживание состояния:** Отслеживает ход выполнения рабочего процесса, потребляя из темы `queue-events`.
*   **Динамическое создание экземпляров заданий:** Взаимодействует с API Kubernetes для динамического запуска и управления заданиями, необходимыми для данного рабочего процесса.
*   **API и отчетность:** Предоставляет RESTful API для инициирования рабочих процессов и запроса их статуса.

**Технологии:** Python, FastAPI (для реализации API), Pydantic, `python-kubernetes`, `aiokafka`, ArangoDB.

#### 4.2. Сбор данных: `loader-*`: Сервисы приема данных

Семейство микросервисов `loader-*` — это специализированные агенты приема данных. Каждый из них отвечает за подключение к внешнему источнику, получение данных и их публикацию в виде событий в Apache Kafka:

*   **`loader-producer`:** Базовый модуль, предназначенный для высокопроизводительной массовой загрузки данных.
*   **`loader-api-*`:** Специализированные модули для работы с историческими данными через REST API.
*   **`loader-ws-*`:** Модули, обрабатывающие потоковые данные в реальном времени через соединения WebSocket.

Каждый модуль настраивается с помощью переменных среды, взаимодействует с темой `queue-control` для получения команд и отправляет отчеты о состоянии в тему `queue-events`.

**Технологии:** Python, `aiohttp` (для REST), `websockets` (для WebSocket), `aiokafka`, `uvloop`, `orjson`.

#### 4.3. Хранение данных: `arango-connector` — Сервис сохранения

Сервис `arango-connector` функционирует как высокоэффективный приемник данных, устраняя разрыв между потоком событий в реальном времени в Kafka и уровнем постоянного хранения в ArangoDB:
*   **Извлечение данных:** Потребление сообщений из соответствующих тем Kafka.
*   **Оптимизация хранения:** Агрегация данных и их хранение в ArangoDB с учетом оптимизации производительности.
*   **Идемпотентные записи:** Использует операции UPSERT для обеспечения возможности повторной обработки данных без создания дублирующих записей, что является критически важной функцией для отказоустойчивых систем.
*   **Обработка ошибок:** Регистрация неверных или поврежденных данных при сохранении непрерывности обслуживания.

**Технологии:** Python, `aioarango`, `aiokafka`.

#### 4.4. Аналитический уровень: `graph-builder` и `gnn-trainer` — ядро аналитики и машинного обучения

Этот набор сервисов составляет аналитическое и машинное ядро платформы:

*   **`graph-builder`:** Преобразует входящие данные в графовые структуры, подходящие для последующего анализа.
*   **`gnn-trainer`:** Обучает модели графовых нейронных сетей (GNN) на основе сформированных графов.

**Технологии:** Python, `aioarango`, `PyTorch`, `PyTorch Geometric (PyG)`, `minio-py`.

#### 4.5. `dummy-service`: Утилита для диагностики и тестирования

`dummy-service` разработан как вспомогательный инструмент для тестирования и моделирования. Он используется для проверки подключения к Kafka, имитации поведения сервисов и генерации нагрузки для тестирования производительности и отказоустойчивости системы.

**Технологии:** Python, FastAPI, `aiokafka`, `loguru`, `prometheus_client`.